{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from crawler import async_cache_pages, urls_list\n",
    "from features import construct_structural_features, feature_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# edX does not work as some content seems to be dynamically downloaded\n",
    "folders = [\"general2\"]\n",
    "\n",
    "positives, negatives = urls_list(folders)\n",
    "async_cache_pages(positives + negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "urls = [positives[0], negatives[0]]\n",
    "labels = [True, False]\n",
    "features = [\"button_count\", \"a_count\"]\n",
    "\n",
    "construct_structural_features(urls, labels, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = sorted(list(feature_functions.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_val(df, selected_features, estimator=RandomForestClassifier(), cv=3):\n",
    "    X = df[selected_features]\n",
    "    y = df[\"label\"]\n",
    "    \n",
    "    return cross_val_score(estimator, X, y, cv=cv, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls_pos, urls_neg = urls_list([\"general2\"])\n",
    "urls = urls_pos + urls_neg\n",
    "labels = [True] * len(urls_pos) + [False] * len(urls_neg)\n",
    "\n",
    "results_means = []\n",
    "results_stds = []\n",
    "\n",
    "df = construct_structural_features(urls, labels, all_features)\n",
    "\n",
    "# iterate over all features and train on this feature alone\n",
    "for feature in all_features:\n",
    "    # Cross val with the selected feature alone\n",
    "    scores = cross_val(df, [feature])\n",
    "    \n",
    "    results_means.append(np.mean(scores))\n",
    "    results_stds.append(np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same thing, but with same ratio of positive and negative examples\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "urls_pos, urls_neg = urls_list([\"general2\"])\n",
    "\n",
    "# Same number of negative and positive examples\n",
    "urls = urls_pos + random.sample(urls_neg, len(urls_pos))\n",
    "labels = [True] * len(urls_pos) + [False] * len(urls_pos)\n",
    "\n",
    "results_unbiased_means = []\n",
    "results_unbiased_stds = []\n",
    "\n",
    "df_unbiased = construct_structural_features(urls, labels, all_features)\n",
    "\n",
    "# iterate over all features and train on one feature alone\n",
    "for feature in all_features:\n",
    "    # Cross val with the selected feature alone\n",
    "    scores = cross_val(df_unbiased, [feature])\n",
    "    \n",
    "    results_unbiased_means.append(np.mean(scores))\n",
    "    results_unbiased_stds.append(np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "index = np.arange(len(results_means))\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "bar_width = 0.35\n",
    "axis_font_size = 18\n",
    "\n",
    "plt.bar(index, results_means, bar_width, yerr=results_stds, color='tab:red', label=\"Biased estimator\")\n",
    "plt.bar(index + bar_width, results_unbiased_means, bar_width, yerr=results_unbiased_stds, label=\"Unbiased estimator\")\n",
    "\n",
    "plt.xlabel(\"Feature\", fontsize=axis_font_size)\n",
    "plt.ylabel(\"Cross validation f1 score\", fontsize=axis_font_size)\n",
    "plt.xticks(index + bar_width / 2, all_features, fontsize=14)\n",
    "\n",
    "#plt.axhline(y=0.5, color='tab:brown', alpha=0.7, linewidth=1)\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "plt.savefig(os.path.join(\"figures\", \"feature_score_biased_unbiased_f1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "X = df_unbiased.drop(\"label\", axis=1)\n",
    "y = df_unbiased[\"label\"]\n",
    "\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_importances = rf.feature_importances_\n",
    "feature_importances_stds = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "index = np.arange(len(results_means))\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "bar_width = 0.35\n",
    "axis_font_size = 18\n",
    "\n",
    "plt.bar(index, results_unbiased_means, bar_width, yerr=results_unbiased_stds, label=\"Unbiased estimator\")\n",
    "plt.bar(index + bar_width, feature_importances, bar_width, color='tab:gray', yerr=feature_importances_stds, label=\"Feature importances\")\n",
    "\n",
    "plt.xlabel(\"Feature\", fontsize=axis_font_size)\n",
    "plt.ylabel(\"Cross validation f1 score / Feature importance\", fontsize=axis_font_size)\n",
    "plt.xticks(index + bar_width / 2, all_features, fontsize=14)\n",
    "\n",
    "#plt.axhline(y=0.5, color='tab:brown', alpha=0.7, linewidth=1)\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "plt.savefig(os.path.join(\"figures\", \"feature_importance_and_feature_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_score(df, selected_features, estimator=RandomForestClassifier()):\n",
    "    X = df[selected_features]\n",
    "    y = df[\"label\"]\n",
    "    \n",
    "    estimator.fit(X, y)\n",
    "    y_pred = estimator.predict(X)\n",
    "    \n",
    "    return f1_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_features = [\"a_count\", \"button_count\", \"h1_count\", \"h2_count\", \"h3_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_estims_list = range(1, 21)\n",
    "score_means = []\n",
    "score_stds = []\n",
    "train_scores = []\n",
    "features = good_features\n",
    "\n",
    "for n_estims in n_estims_list:\n",
    "    scores = cross_val(df_unbiased, features, estimator=RandomForestClassifier(n_estimators=n_estims))\n",
    "    \n",
    "    score_means.append(np.mean(scores))\n",
    "    score_stds.append(np.std(scores))\n",
    "    \n",
    "    train_score = training_score(df_unbiased, features, estimator=RandomForestClassifier(n_estimators=n_estims))\n",
    "    train_scores.append(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(n_estims_list, score_means)\n",
    "plt.plot(n_estims_list, train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM is not supposed to work well, because \". SVMs do not perform well on highly skewed/imbalanced data sets. These are training data sets in which the number of samples that fall in one of the classes far outnumber those that are a member of the other class. Customer churn data sets are typically in this group because when you collect the training set, among a million customers during a particular time period, there would be very few who have actually churned. SMOTING is used to generate artificial samples in the minority class to balance the data set. On the other hand, Logistic Regression is good at handling skewed data sets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "kernels = ['linear', 'sigmoid', 'rbf']\n",
    "score_means = []\n",
    "score_stds = []\n",
    "train_scores = []\n",
    "features = good_features\n",
    "\n",
    "for kernel in kernels:\n",
    "    scores = cross_val(df_unbiased, features, estimator=svm.SVC(kernel=kernel))\n",
    "    \n",
    "    score_means.append(np.mean(scores))\n",
    "    score_stds.append(np.std(scores))\n",
    "    \n",
    "    train_score = training_score(df_unbiased, features, estimator=svm.SVC(kernel=kernel))\n",
    "    train_scores.append(train_score)\n",
    "    \n",
    "plt.plot(score_means)\n",
    "plt.plot(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neigbours = range(1, 40)\n",
    "score_means = []\n",
    "score_stds = []\n",
    "train_scores = []\n",
    "features = good_features\n",
    "\n",
    "for n in n_neigbours:\n",
    "    scores = cross_val(df_unbiased, features, estimator=KNeighborsClassifier(n_neighbors=n))\n",
    "    \n",
    "    score_means.append(np.mean(scores))\n",
    "    score_stds.append(np.std(scores))\n",
    "    \n",
    "    train_score = training_score(df_unbiased, features, estimator=KNeighborsClassifier(n_neighbors=n))\n",
    "    train_scores.append(train_score)\n",
    "    \n",
    "plt.plot(n_neigbours, score_means)\n",
    "plt.plot(n_neigbours, train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "layers = range(1, 15)\n",
    "score_means = []\n",
    "score_stds = []\n",
    "train_scores = []\n",
    "features = good_features\n",
    "\n",
    "for layer in layers:\n",
    "    scores = cross_val(df_unbiased, features, estimator=MLPClassifier(hidden_layer_sizes=(30,)*layer, random_state=1))\n",
    "    \n",
    "    score_means.append(np.mean(scores))\n",
    "    score_stds.append(np.std(scores))\n",
    "    \n",
    "    train_score = training_score(df_unbiased, features, estimator=MLPClassifier(hidden_layer_sizes=(30,)*layer, random_state=1))\n",
    "    train_scores.append(train_score)\n",
    "    \n",
    "plt.plot(layers, score_means)\n",
    "plt.plot(layers, train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg_terms = np.arange(0.1, 1, 0.05)\n",
    "score_means = []\n",
    "score_stds = []\n",
    "train_scores = []\n",
    "features = good_features\n",
    "\n",
    "for reg in reg_terms:\n",
    "    scores = cross_val(df_unbiased, features, estimator=LogisticRegression(C=reg, random_state=1))\n",
    "    \n",
    "    score_means.append(np.mean(scores))\n",
    "    score_stds.append(np.std(scores))\n",
    "    \n",
    "    train_score = training_score(df_unbiased, features, estimator=LogisticRegression(C=reg, random_state=1))\n",
    "    train_scores.append(train_score)\n",
    "    \n",
    "plt.plot(reg_terms, score_means)\n",
    "plt.plot(reg_terms, train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "alphas = np.arange(0.1, 1000, 5)\n",
    "score_means = []\n",
    "score_stds = []\n",
    "train_scores = []\n",
    "features = good_features\n",
    "\n",
    "for alpha in alphas:\n",
    "    scores = cross_val(df_unbiased, features, estimator=MultinomialNB(alpha=alpha))\n",
    "    \n",
    "    score_means.append(np.mean(scores))\n",
    "    score_stds.append(np.std(scores))\n",
    "    \n",
    "    train_score = training_score(df_unbiased, features, estimator=MultinomialNB(alpha=alpha))\n",
    "    train_scores.append(train_score)\n",
    "    \n",
    "plt.plot(alphas, score_means)\n",
    "plt.plot(alphas, train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyse_classification(X, y, predictor, seed=0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed)\n",
    "    predictor.fit(X_train, y_train)\n",
    "    y_pred = predictor.predict(X_test)\n",
    "    \n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df[good_features]\n",
    "y = df[\"label\"]\n",
    "\n",
    "print(cross_val_score(KNeighborsClassifier(n_neighbors=5), X, y))\n",
    "print(cross_val_score(KNeighborsClassifier(n_neighbors=5), X, y, scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyse_classification(X, y, KNeighborsClassifier(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_unbiased[good_features]\n",
    "y = df_unbiased[\"label\"]\n",
    "\n",
    "print(cross_val_score(KNeighborsClassifier(n_neighbors=5), X, y))\n",
    "print(cross_val_score(KNeighborsClassifier(n_neighbors=5), X, y, scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyse_classification(X, y, KNeighborsClassifier(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
