{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from crawler import async_cache_pages, urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# edX does not work as some content seems to be dynamically downloaded\n",
    "folders = [\"coursera\", \"general\"]\n",
    "\n",
    "positives, negatives = urls_list(folders)\n",
    "async_cache_pages(positives + negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_functions = {\n",
    "        #\"url\": url,\n",
    "        #\"label\": label,\n",
    "        \"a_count\": lambda soup: len(soup.find_all(\"a\")),\n",
    "        \"iframe_count\": lambda soup: len(soup.find_all(\"iframe\")),\n",
    "        \"h1_count\": lambda soup: len(soup.find_all(\"h1\")),\n",
    "        \"h2_count\": lambda soup: len(soup.find_all(\"h2\")),\n",
    "        \"h3_count\": lambda soup: len(soup.find_all(\"h3\")),\n",
    "        \"video_count\": lambda soup: len(soup.find_all(\"video\")),\n",
    "        \"button_count\": lambda soup: len(soup.find_all(\"button\"))\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from crawler import get_cached, is_cached\n",
    "\n",
    "def construct_df_features(urls, labels, features):\n",
    "    row_list = []\n",
    "    features_func = [feature_functions[feat] for feat in features]\n",
    "    columns = [\"url\", \"label\"] + features\n",
    "\n",
    "    for url, label in zip(urls, labels):\n",
    "        if is_cached(url):\n",
    "            soup = BeautifulSoup(get_cached(url), \"lxml\")\n",
    "\n",
    "        row = [url, label] + [func(soup) for func in features_func]\n",
    "\n",
    "        row_list.append(row)\n",
    "\n",
    "    df = pd.DataFrame(row_list, columns=columns)\n",
    "    df = df.set_index(\"url\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "urls = [positives[0], negatives[0]]\n",
    "labels = [True, False]\n",
    "features = [\"button_count\", \"a_count\"]\n",
    "\n",
    "construct_df_features(urls, labels, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = sorted(list(feature_functions.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_val(df, selected_features, estimator=RandomForestClassifier(), cv=3):\n",
    "    X = df[selected_features]\n",
    "    y = df[\"label\"]\n",
    "    \n",
    "    return cross_val_score(rf_estimator, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls_pos, urls_neg = urls_list([\"coursera\", \"general\"])\n",
    "urls = urls_pos + urls_neg\n",
    "labels = [True] * len(urls_pos) + [False] * len(urls_neg)\n",
    "\n",
    "results_means = []\n",
    "results_stds = []\n",
    "\n",
    "df = construct_df_features(urls, labels, all_features)\n",
    "\n",
    "# iterate over all features and train on this feature alone\n",
    "for feature in all_features:\n",
    "    # Cross val with the selected feature alone\n",
    "    scores = cross_val(df, [feature])\n",
    "    \n",
    "    results_means.append(np.mean(scores))\n",
    "    results_stds.append(np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same thing, but with same ratio of positive and negative examples\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "urls_pos, urls_neg = urls_list([\"coursera\", \"general\"])\n",
    "\n",
    "# Same number of negative and positive examples\n",
    "urls = urls_pos + random.sample(urls_neg, len(urls_pos))\n",
    "labels = [True] * len(urls_pos) + [False] * len(urls_pos)\n",
    "\n",
    "results_unbiased_means = []\n",
    "results_unbiased_stds = []\n",
    "\n",
    "df_unbiased = construct_df_features(urls, labels, all_features)\n",
    "\n",
    "# iterate over all features and train on one feature alone\n",
    "for feature in all_features:\n",
    "    # Cross val with the selected feature alone\n",
    "    scores = cross_val(df_unbiased, [feature])\n",
    "    \n",
    "    results_unbiased_means.append(np.mean(scores))\n",
    "    results_unbiased_stds.append(np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "index = np.arange(len(results_means))\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "bar_width = 0.35\n",
    "axis_font_size = 18\n",
    "\n",
    "\n",
    "plt.bar(index, results_means, bar_width, yerr=results_stds, color='tab:red', label=\"Biased estimator\")\n",
    "plt.xlabel(\"Feature\", fontsize=axis_font_size)\n",
    "plt.ylabel(\"Cross validation score\", fontsize=axis_font_size)\n",
    "plt.xticks(index, all_features)\n",
    "\n",
    "plt.bar(index + bar_width, results_unbiased_means, bar_width, yerr=results_unbiased_stds, label=\"Unbiased estimator\")\n",
    "plt.xlabel(\"Feature\", fontsize=axis_font_size)\n",
    "plt.ylabel(\"Cross validation score\", fontsize=axis_font_size)\n",
    "plt.xticks(index + bar_width / 2, all_features, fontsize=14)\n",
    "\n",
    "plt.axhline(y=0.5, color='tab:brown', alpha=0.7, linewidth=1)\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "plt.savefig(os.path.join(\"figures\", \"feature_importance_biased_estimator\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
