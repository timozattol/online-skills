{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "PCA on top?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from crawler import async_cache_pages, urls_list\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folders = [\"general2\"]\n",
    "\n",
    "positives, negatives = urls_list(folders)\n",
    "async_cache_pages(positives + negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same number of negative and positive examples\n",
    "urls = positives + random.sample(negatives, len(positives))\n",
    "labels = [True] * len(positives) + [False] * len(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from features import construct_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = construct_text_df(urls, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sample(5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[\"visible_text\"]\n",
    "y = df.label#.replace([False, True], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_counts = count_vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats = count_vect.get_feature_names()\n",
    "feats[10000:10000 + 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_feats_in_doc(X_tfidf, feats, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_feats_in_doc(X_tfidf, feats, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_feats_in_doc(X_tfidf, feats, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_new = [\"course submit\", \"education learning\", \"python coursera\", \"submit button\", \"medical hospital\"]\n",
    "predicted = pipeline.predict(docs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for doc, category in zip(docs_new, predicted):\n",
    "    print(doc, \"==>\", category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from features import analyse_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "analyse_classification(X, y, pipeline2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking all training data (more negatives than positives)\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "False       0.78      0.98      0.87        50\n",
    "\n",
    "True       0.92      0.44      0.59        25\n",
    "\n",
    "avg / total       0.82      0.80      0.78        75\n",
    "\n",
    "[[49  1]\n",
    "\n",
    " [14 11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline3 = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "analyse_classification(X, y, pipeline3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline3.decision_function(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem ? 0.84 quite high. Overfitting because 6-7 pages in the same platform ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_urls_true = [\n",
    "    \"https://www.wallstreetprep.com/self-study-programs/oil-and-gas-modeling/\",\n",
    "    \"https://www.wallstreetprep.com/self-study-programs/restructuring-modeling/\",\n",
    "    \"https://www.wallstreetprep.com/self-study-programs/bank-and-fig-modeling/\",\n",
    "    \"https://www.wallstreetprep.com/self-study-programs/adv-lbo-modeling/\",\n",
    "    \"https://www.educba.com/course/online-investment-banking-training-courses/\",\n",
    "    \"https://www.creativelive.com/courses/find-your-niche-and-build-your-family-photography-business-julia-kelleher\",\n",
    "    \"https://www.creativelive.com/courses/lightroom-cc-photo-editing-the-complete-guide-ben-willmore\",\n",
    "    \"https://www.creativelive.com/courses/portrait-compositing-from-start-to-finish-matt-kloskowski?via=class-list-collection_3\",\n",
    "    \"https://onlinecoursemasters.com/\",\n",
    "    \"https://ocw.mit.edu/courses/mathematics/18-01-single-variable-calculus-fall-2006/index.htm\",\n",
    "    \"http://tutorial.math.lamar.edu/Classes/CalcI/CalcI.aspx\",\n",
    "    \"https://www.khanacademy.org/math/calculus-home\",\n",
    "    \"https://www.coursera.org/learn/calculus1\",\n",
    "    \"https://www.simplilearn.com/blockchain-certification-training\",\n",
    "]\n",
    "\n",
    "new_urls_false = [\n",
    "    \"https://twitter.com/?lang=en\",\n",
    "    \"http://iamafoodblog.com/\",\n",
    "    \"http://iamafoodblog.com/category/recipes/\",\n",
    "    \"https://keepvid.com/sites/download-youtube-video.html\",\n",
    "    \"https://en.wikipedia.org/wiki/Massive_open_online_course\",\n",
    "    \"https://github.com/\",\n",
    "    \"https://github.com/features\",\n",
    "    \"https://news.ycombinator.com/\",\n",
    "    \"https://www.schneems.com/2017/11/14/wtf-is-a-source-map/\",\n",
    "    \"https://medium.freecodecamp.org/using-svg-as-placeholders-more-image-loading-techniques-bed1b810ab2c\"\n",
    "]\n",
    "\n",
    "\n",
    "async_cache_pages(new_urls_true + new_urls_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Not really using these labels anyway\n",
    "new_labels_true = [True] * len(new_urls_true)\n",
    "new_labels_false = [False] * len(new_urls_false)\n",
    "\n",
    "df_true = construct_text_df(new_urls_true, new_labels_true)\n",
    "df_false = construct_text_df(new_urls_false, new_labels_false)\n",
    "\n",
    "X_new_true = df_true[\"visible_text\"]\n",
    "X_new_false = df_false[\"visible_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline3.predict(X_new_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline3.decision_function(X_new_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline3.predict(X_new_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline3.decision_function(X_new_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, works well because of the duplication in the training set, but we see that there are no false positive, and the false negatives have a value close to zero in the decision function, meaning it is \"unsure\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folders = [\"general3\"]\n",
    "\n",
    "positives, negatives = urls_list(folders)\n",
    "async_cache_pages(positives + negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same number of negative and positive examples\n",
    "urls = positives + random.sample(negatives, len(positives))\n",
    "labels = [True] * len(positives) + [False] * len(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = construct_text_df(urls, labels)\n",
    "X = df[\"visible_text\"]\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multinomial NB\n",
    "analyse_classification(X, y, pipeline2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "analyse_classification(X, y, pipeline3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(pipeline3, os.path.join('saved', 'models', 'log_reg_pipeline_general3.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
