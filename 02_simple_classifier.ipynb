{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Project paths\n",
    "\n",
    "manual_path = \"webpages/manually_selected\"\n",
    "\n",
    "def urls_path(folder, positive=True):\n",
    "    pos = \"positive\" if positive else \"negative\"\n",
    "    path = \"{}/urls/{}-{}.txt\".format(manual_path, folder, pos)\n",
    "    return path\n",
    "\n",
    "def urls_list(folder, positive=True):\n",
    "    path = urls_path(folder, positive)\n",
    "    \n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        urls = list(l.strip() for l in f if l[0] != \"#\")\n",
    "    f.close()\n",
    "    \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keep visible text\n",
    "\n",
    "def tag_visible(element):\n",
    "    '''Keep only visible elements'''\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def extract_visible(soup):\n",
    "    text = soup.html.body.findAll(text=True)\n",
    "    s = ' '.join(filter(tag_visible, text))\n",
    "    return re.sub(\"\\s\\s+\" , \" \", s) # remove all double spaces and tabs/newlines/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positives = urls_list(\"coursera\") + urls_list(\"general\")\n",
    "negatives = urls_list(\"coursera\", False) + urls_list(\"general\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_features(soup):\n",
    "    # number of links\n",
    "    a_count = len(soup.find_all(\"a\"))\n",
    "    \n",
    "    # number of iframes\n",
    "    iframe_count = len(soup.find_all(\"iframe\"))\n",
    "    \n",
    "    \n",
    "    return [a_count, iframe_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for url in positives[:10]:\n",
    "    row_list.append([url, True] + construct_features(get_soup(url)))\n",
    "    \n",
    "for url in negatives[:10]:\n",
    "    row_list.append([url, False] + construct_features(get_soup(url)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(row_list, columns=[\"url\", \"label\", \"a_count\", \"iframe_count\"])\n",
    "df = df.set_index(\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_estimator = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf_estimator, X, y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import grequests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def url_to_filename(url):\n",
    "    return url.replace(\"/\", \",\")\n",
    "\n",
    "def filename_to_url(filename):\n",
    "    return filename.replace(\",\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dumps_path = manual_path + \"/dumps\"\n",
    "\n",
    "def dump_path(url):\n",
    "    return \"{}/{}\".format(dumps_path, url_to_filename(url))\n",
    "\n",
    "def delete_all_files(folder):\n",
    "    for file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "def is_cached(url):\n",
    "    return os.path.isfile(dump_path(url))\n",
    "\n",
    "def get_cached(url):\n",
    "    if not is_cached(url):\n",
    "        raise Exception(\"{} not cached\".format(url))\n",
    "\n",
    "    with open(dump_path(url), 'r') as f:\n",
    "        s = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    return s\n",
    "\n",
    "def get_original_url(response):\n",
    "    return response.history[0].url if response.history else response.url\n",
    "        \n",
    "\n",
    "def async_download_pages(urls, delete_cache=False, threads=15):\n",
    "    if delete_cache:\n",
    "        delete_all_files(dumps_path)\n",
    "\n",
    "    # Only request for pages not already in the dump folder\n",
    "    reqs = [grequests.get(url) for url in urls if not is_cached(url)]\n",
    "    \n",
    "    for r in grequests.imap(reqs, size=threads):\n",
    "        if r.status_code == 200:\n",
    "            with open(dump_path(get_original_url(r)), 'w') as f:\n",
    "                f.write(r.text)\n",
    "            f.close()\n",
    "        else:\n",
    "            print(\"Error while downloading: {}. Status code: {}\".format(r.url, r.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "async_download_pages([\"https://www.coursera.org/\", \"https://www.coursera.org/enterprise\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_urls = [url \n",
    "            for pos in (True, False) \n",
    "            for folder in (\"coursera\", \"edX\", \"general\") \n",
    "            for url in urls_list(folder, pos)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download all pages asynchronously\n",
    "from random import sample\n",
    "async_download_pages(sample(all_urls, len(all_urls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try again with all the pages\n",
    "\n",
    "row_list = []\n",
    "\n",
    "positives = [url for folder in [\"coursera\", \"edX\", \"general\"] for url in urls_list(folder, True)]\n",
    "negatives = [url for folder in [\"coursera\", \"edX\", \"general\"] for url in urls_list(folder, False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for url in positives:\n",
    "    try:\n",
    "        soup = BeautifulSoup(get_cached(url), \"lxml\")\n",
    "        row_list.append([url, True] + construct_features(soup))\n",
    "    except:\n",
    "        print(\"{} not cached\".format(url))\n",
    "    \n",
    "for url in negatives:\n",
    "    try:\n",
    "        soup = BeautifulSoup(get_cached(url), \"lxml\")\n",
    "        row_list.append([url, False] + construct_features(soup))\n",
    "    except:\n",
    "        print(\"{} not cached\".format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(row_list, columns=[\"url\", \"label\", \"a_count\", \"iframe_count\"])\n",
    "df = df.set_index(\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_estimator = RandomForestClassifier()\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "scores = cross_val_score(rf_estimator, X, y, cv=5, )\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
